{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required functions\n",
    "import GEOparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats.mstats import zscore\n",
    "import time\n",
    "#Time sleep to prevent crashes\n",
    "time.sleep(1)\n",
    "#Change this to your working directory\n",
    "WORKDIR = '/Users/MaayanLab/Desktop/Allie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define merge function for combining sample lists\n",
    "def merge(dict1, dict2): \n",
    "        res = {**dict1, **dict2} \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define characteristic direction function\n",
    "def chdir(data, sampleclass, genes, gamma=1., sort=True, calculate_sig=False, nnull=10, sig_only=False, norm_vector=True):\n",
    "        data.astype(float)\n",
    "        #sampleclass = np.array(map(int, sampleclass))\n",
    "        m_non0 = sampleclass != 0\n",
    "        m1 = sampleclass[m_non0] == 1\n",
    "        m2 = sampleclass[m_non0] == 2\n",
    "\n",
    "        data = data[:, m_non0]\n",
    "        data = zscore(data)\n",
    "\n",
    "        n1 = m1.sum() # number of controls\n",
    "        n2 = m2.sum() # number of experiments\n",
    "\n",
    "        meanvec = data[:,m2].mean(axis=1) - data[:,m1].mean(axis=1) \n",
    "\n",
    "        pca = PCA(n_components=None)\n",
    "        pca.fit(np.array(data.T))\n",
    "\n",
    "        cumsum = pca.explained_variance_ratio_\n",
    "        keepPC = len(cumsum[cumsum > 0.001])\n",
    "\n",
    "        v = pca.components_[0:keepPC].T\n",
    "        r = pca.transform(data.T)[:,0:keepPC]\n",
    "        dd = ( np.dot(r[m1].T,r[m1]) + np.dot(r[m2].T,r[m2]) ) / float(n1+n2-2)\n",
    "        sigma = np.mean(np.diag(dd))\n",
    "\n",
    "        shrunkMats = np.linalg.inv(gamma*dd + sigma*(1-gamma)*np.eye(keepPC))\n",
    "        b = np.dot(v, np.dot(np.dot(v.T, meanvec), shrunkMats))\n",
    "\n",
    "        if norm_vector:\n",
    "            b /= np.linalg.norm(b)\n",
    "\n",
    "        grouped = zip([abs(item) for item in b],b,genes)\n",
    "        if sort:\n",
    "            grouped = sorted(grouped,key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        if not calculate_sig: # return sorted b and genes.\n",
    "            res = [(item[1],item[2]) for item in grouped]\n",
    "            return res\n",
    "        else: # generate a null distribution of chdirs\n",
    "            nu = n1 + n2 - 2\n",
    "            y1 = np.random.multivariate_normal(np.zeros(keepPC), dd, nnull).T * np.sqrt(nu / chi2.rvs(nu,size=nnull))\n",
    "            y2 = np.random.multivariate_normal(np.zeros(keepPC), dd, nnull).T * np.sqrt(nu / chi2.rvs(nu,size=nnull))\n",
    "            y = y2 - y1\n",
    "\n",
    "            nullchdirs = []\n",
    "            for col in y.T:\n",
    "                bn = np.dot(np.dot(np.dot(v,shrunkMats), v.T), np.dot(col,v.T))\n",
    "                bn /= np.linalg.norm(bn)\n",
    "                bn = bn ** 2\n",
    "                bn.sort()\n",
    "                bn = bn[::-1] ## sort in decending order\n",
    "                nullchdirs.append(bn)\n",
    "\n",
    "            nullchdirs = np.array(nullchdirs).T\n",
    "            nullchdirs = nullchdirs.mean(axis=1)\n",
    "            b_s = b ** 2 \n",
    "            b_s.sort()\n",
    "            b_s = b_s[::-1] # sorted b in decending order\n",
    "            relerr = b_s / nullchdirs ## relative error\n",
    "            # ratio_to_null\n",
    "            ratios = np.cumsum(relerr)/np.sum(relerr)- np.linspace(1./len(meanvec),1,len(meanvec))\n",
    "            res = [(item[1],item[2], ratio) for item, ratio in zip(grouped, ratios)] \n",
    "            print('Number of significant genes: %s'%(np.argmax(ratios)+1))\n",
    "            if sig_only:\n",
    "                return res[0:np.argmax(ratios)+1]\n",
    "            else:\n",
    "                return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Microarray Analysis Pipeline\n",
    "def micro_analysis(accession_id, control_samples, treated_samples):\n",
    "    #Creating a dictionary of assigned control and treated samples \n",
    "      \n",
    "    control_samples = { i : 'control' for i in control_samples }\n",
    "    treated_samples = { i : 'treated' for i in treated_samples }\n",
    "    all_samples = merge(control_samples, treated_samples)\n",
    "    \n",
    "    #Parse the GEO data using the Accession ID\n",
    "    gse = GEOparse.get_GEO(geo=accession_id, destdir=\"./\")\n",
    "    #Create a list of samples to use in the development of the expression matrix\n",
    "    list_samples = list(all_samples.keys())\n",
    "    \n",
    "    #Visualization of expression matrix\n",
    "    pivoted_samples = gse.pivot_samples('VALUE')[list_samples]\n",
    "    pivoted_samples.head()\n",
    "    #Determine the total amount of probes used in the study\n",
    "    pivoted_samples_average = pivoted_samples.median(axis=1)\n",
    "    #Filtering out unexpressed probes\n",
    "    expression_threshold = pivoted_samples_average.quantile(0.3)\n",
    "    expressed_probes = pivoted_samples_average[pivoted_samples_average >= expression_threshold].index.tolist()\n",
    "    \n",
    "    #Redefine expression data using only the expressed probes\n",
    "    exprsdata = gse.pivot_samples(\"VALUE\").loc[expressed_probes]\n",
    "    exprsdata = exprsdata.T\n",
    "    #Deletes additional samples that aren't being analyzed\n",
    "    exprsdata = exprsdata[exprsdata.index.isin(list_samples)]\n",
    "    #Drop any probe columns where expression data is missing or negative\n",
    "    exprsdata.dropna(axis = 1)\n",
    "    \n",
    "    #Quantile normalization of data\n",
    "    rank_mean = exprsdata.stack().groupby(exprsdata.rank(method='first').stack().astype(int)).mean()\n",
    "    exprsdata.rank(method='min').stack().astype(int).map(rank_mean).unstack().dropna(axis=1)\n",
    "    #Making Dataframe of samples\n",
    "    samplesDf = pd.DataFrame.from_dict(all_samples, orient = 'index', columns = ['type'])\n",
    "    samplesDf.reset_index(inplace=True)\n",
    "    \n",
    "    #Transpose data matrix for sorting, index correlated to probe IDs\n",
    "    exprsdata = exprsdata.T\n",
    "    #Upload annotation file as dictionary\n",
    "    dict1 = {}\n",
    "    with open(WORKDIR + '/probe2gene.txt') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            (platform, probe, symbol) = line.split()\n",
    "            dict1[probe] = symbol\n",
    "    #Reset index and replace with gene symbols, view as dataframe\n",
    "    exprsdata = pd.DataFrame(exprsdata)\n",
    "    exprsdata.index = exprsdata.index.astype(str, copy=False)\n",
    "    exprsdata['symbol'] = exprsdata.index.to_series().map(dict1)\n",
    "    exprsdata.reset_index(inplace=True)\n",
    "    data = exprsdata.set_index('symbol')\n",
    "    \n",
    "    #Drop probe id column\n",
    "    data = data.drop('ID_REF', axis=1)\n",
    "    #Drop rows that aren't associated with a particular gene symbol\n",
    "    data = data.reset_index().dropna().set_index('symbol')\n",
    "    \n",
    "    #Utilize warning statements\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    #Make sample classes, ensure that there is a distinction between control/treated samples\n",
    "    data_cd = {}\n",
    "    sample_classes = {}\n",
    "    sample_class = np.zeros(data.shape[1], dtype=np.int32)\n",
    "    sample_class[samplesDf['type'].values == 'control'] = 1\n",
    "    sample_class[samplesDf['type'].values == 'treated'] = 2\n",
    "    sample_classes = sample_class\n",
    "    \n",
    "    #CD results\n",
    "    cd_res = chdir(data.values, sample_classes, data.index, gamma=.5, sort=False, calculate_sig=False)\n",
    "    cd_coefs = np.array(list(map(lambda x: x[0], cd_res)))\n",
    "    srt_idx = np.abs(cd_coefs).argsort()[::-1]\n",
    "    cd_coefs = cd_coefs[srt_idx][:600]\n",
    "    sorted_DEGs = data.index[srt_idx][:600]\n",
    "    up_genes = dict(zip(sorted_DEGs[cd_coefs > 0], cd_coefs[cd_coefs > 0]))\n",
    "    dn_genes = dict(zip(sorted_DEGs[cd_coefs < 0], cd_coefs[cd_coefs < 0]))\n",
    "    data_cd['up'] = up_genes\n",
    "    data_cd['dn'] = dn_genes\n",
    "    \n",
    "    #Retrieve up and down gene sets\n",
    "    up_list = list(up_genes.keys())\n",
    "    dn_list = list(dn_genes.keys())\n",
    "    #Up genes and down genes\n",
    "    return up_list, dn_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read metadata file\n",
    "metadata = pd.read_csv(WORKDIR + '/example_metadata.csv')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run analysis over studies in the metadata file, printing a list of the up and down genes\n",
    "up_data = {}\n",
    "dn_data = {}\n",
    "for i in range(0,len(metadata.index)):\n",
    "    accession_id = metadata.iloc[i]['GEO Accession Number']\n",
    "    control_samples = metadata.iloc[i]['Control Samples']\n",
    "    treated_samples = metadata.iloc[i]['Treated Samples']\n",
    "    cell_type = str(metadata.iloc[i]['Cell Type'])\n",
    "    phys = str(metadata.iloc[i]['Altered Condition'])\n",
    "    drug = str(metadata.iloc[i]['Drug Name'])\n",
    "    gene = str(metadata.iloc[i]['Name of the Perturbed Gene'])\n",
    "    gene_type = str(metadata.iloc[i]['Gene Alteration'])\n",
    "    platform = str(metadata.iloc[i]['GEO Platform'])\n",
    "    metadata_list = [platform, cell_type, phys, drug, gene, gene_type]\n",
    "    control_samples = control_samples.split(',')\n",
    "    control_samples = [c.strip(' ') for c in control_samples]\n",
    "    treated_samples = treated_samples.split(',')\n",
    "    treated_samples = [t.strip(' ') for t in treated_samples]\n",
    "    DEGs = micro_analysis(accession_id, control_samples, treated_samples)\n",
    "    up_genes, dn_genes = DEGs\n",
    "    up_data[accession_id + ' ' + str(metadata_list) + ' up'] = up_genes\n",
    "    dn_data[accession_id + str(metadata_list) + ' dn'] = dn_genes\n",
    "    print(up_data, dn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Jaccard Index function from Megan's code\n",
    "def jaccardIndex(listA,listB):\n",
    "    intersection = len(set(listA) & set(listB))\n",
    "    JI = intersection/(len(listA)+len(listB)-intersection)\n",
    "    return(JI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merged up and down data\n",
    "all_data = merge(up_data, dn_data)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract labels from lists of up/down genes\n",
    "all_terms = [k for k,v in all_data.items()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up matrix store the calculations of the Jaccard indices\n",
    "matrix = []\n",
    "\n",
    "for term1 in all_terms:\n",
    "    geneset1 = all_data[term1]\n",
    "    row = []\n",
    "    for term2 in all_terms:\n",
    "        geneset2 = all_data[term2]\n",
    "        sim_score = jaccardIndex(geneset1,geneset2)\n",
    "        row.append(sim_score)\n",
    "    matrix.append(row)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final version of the desired format of  labels\n",
    "final_terms = []\n",
    "for term in all_terms:\n",
    "    accession = term.split('[')[0].strip()\n",
    "    platform = term.split('[')[1].split(', ')[0].replace(\"'\",'')\n",
    "    cell_line = term.split('[')[1].split(', ')[1].replace(\"'\",'')\n",
    "    physical_alt = term.split('[')[1].split(', ')[2].replace(\"'\",'')\n",
    "    chemical_alt = term.split('[')[1].split(', ')[3].replace(\"'\",'')\n",
    "    genetic_alt = term.split('[')[1].split(', ')[4].replace(\"'\",'')\n",
    "    genetic_alt_type = term.split('[')[1].split(', ')[5].split(']')[0].replace(\"'\",'')\n",
    "    updown = term.split('] ')[1]\n",
    "#Customize which categories of metadata to include on the labels\n",
    "    final_terms.append(list(['Accession: ' + str(accession), 'Cell Line: ' + str(cell_line), 'Up/Down: ' + str(updown),\n",
    "                            'Platform: ' + str(platform), 'Physical Alteration: ' + str(physical_alt),\n",
    "                            'Chemical Alteration: ' + str(chemical_alt), 'Genetic Alteration: ' + str(genetic_alt) + str(genetic_alt_type)])) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize labels\n",
    "final_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a tab-delimited file\n",
    "clustergrammer_output = open('jaccard_clustergrammer_autophagy.tsv','w')\n",
    "#Number of categories of metadata used, e.g. Accession ID, Cell Line, or Up/Down\n",
    "categories = 7\n",
    "#Shift columns to make room for row labels and write columns\n",
    "for cat in range(0,categories):\n",
    "    clustergrammer_output.write('\\t'*categories + '\\t'.join([x[cat] for x in final_terms]) + '\\n')\n",
    "#Write rows and input jaccard indices   \n",
    "for i in range(0, len(matrix)):\n",
    "    clustergrammer_output.write(final_terms[i][0] + '\\t' + final_terms[i][1] + '\\t' + final_terms[i][2] + '\\t' + final_terms[i][3] + '\\t'+ final_terms[i][4] + '\\t'+ final_terms[i][5] + '\\t'+ final_terms[i][6] + '\\t' + '\\t'.join([str(x) for x in matrix[i]]) + '\\n')\n",
    "\n",
    "clustergrammer_output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
